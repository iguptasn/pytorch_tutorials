{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5e73c43-9d8b-440f-9b0e-bf7044c686d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cd3cd84-eab9-47ce-ad99-e86a94a35a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4c8da69-7c6d-45b2-87bd-3c207fc5dad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# get device for training\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62f45cac-ab6e-41a3-9aae-f38f3a4cb0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define neural network by subclassing nn.Module\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28,512), \n",
    "            nn.ReLU(), \n",
    "            nn.Linear(512, 512), \n",
    "            nn.ReLU(), \n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24c8f802-3073-411a-9c83-893da68f0a98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2ce61137-f8cc-482c-9f13-7fb718450d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.rand(1,28,28, device=device)\n",
    "logits = model(X)\n",
    "pred_probab = nn.Softmax(dim=1)(logits)\n",
    "y_pred = pred_probab.argmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8ea36fe7-840b-45e7-8e49-e99b42d42226",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0162,  0.0550, -0.0485, -0.1115, -0.0713,  0.1006,  0.0743, -0.0884,\n",
       "          0.0174,  0.0422]], device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d46e7be5-9ce2-4bba-a7b2-faba822e6037",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1015, 0.1055, 0.0952, 0.0894, 0.0930, 0.1105, 0.1076, 0.0915, 0.1017,\n",
       "         0.1042]], device='cuda:0', grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_probab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "12ee890d-06b5-430b-ad4d-3b7e6b201dec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5], device='cuda:0')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3ae37f74-97ab-4b49-8897-e95c95bcbced",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('linear_relu_stack.0.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0266, -0.0027,  0.0121,  ...,  0.0248, -0.0183, -0.0178],\n",
       "          [-0.0100,  0.0170, -0.0274,  ..., -0.0066, -0.0259,  0.0235],\n",
       "          [ 0.0285, -0.0312, -0.0129,  ..., -0.0282, -0.0305, -0.0258],\n",
       "          ...,\n",
       "          [-0.0227, -0.0184, -0.0150,  ...,  0.0106,  0.0193, -0.0041],\n",
       "          [-0.0197, -0.0225, -0.0007,  ...,  0.0077,  0.0291, -0.0277],\n",
       "          [-0.0219,  0.0295, -0.0223,  ...,  0.0316, -0.0083,  0.0128]],\n",
       "         device='cuda:0', requires_grad=True)),\n",
       " ('linear_relu_stack.0.bias',\n",
       "  Parameter containing:\n",
       "  tensor([-3.0015e-02, -1.6832e-04, -5.6299e-03,  8.2852e-03,  3.8866e-03,\n",
       "           2.6253e-02,  1.7013e-02,  9.3673e-04, -1.2860e-02,  3.2772e-02,\n",
       "           1.3723e-02, -9.5581e-03,  3.2115e-02, -1.9888e-02, -1.1253e-03,\n",
       "          -2.6112e-03,  2.0083e-02, -2.1564e-02, -1.1684e-03,  3.9821e-04,\n",
       "          -3.4614e-02,  2.6544e-02, -3.4822e-02, -1.7542e-02, -2.5858e-02,\n",
       "          -2.9467e-02,  1.4126e-02,  1.6232e-02, -1.9837e-02, -4.3011e-03,\n",
       "           2.6758e-02,  2.5820e-02,  1.7357e-02,  3.0912e-02, -1.9547e-02,\n",
       "          -1.8263e-02,  2.7939e-02,  9.4244e-04, -3.5368e-02, -2.7611e-02,\n",
       "          -2.4265e-02,  1.8507e-02,  2.4051e-02, -2.5102e-02, -2.6112e-02,\n",
       "           8.5587e-03,  4.5468e-03,  2.1267e-02, -2.2850e-02, -3.3896e-02,\n",
       "           2.3640e-02, -1.6846e-02,  1.9219e-02,  2.6822e-02,  3.3185e-02,\n",
       "          -7.5627e-03,  1.4861e-02,  1.9231e-02, -7.7391e-03, -7.6732e-03,\n",
       "           8.5424e-04, -2.9283e-02,  6.5302e-03,  1.6369e-02,  8.1036e-03,\n",
       "           2.4158e-02, -1.3864e-02, -3.2258e-03, -2.6648e-02,  4.8425e-03,\n",
       "           9.0141e-03, -3.1871e-02, -3.0621e-02,  5.2489e-03, -2.2743e-02,\n",
       "          -3.2925e-02,  1.7477e-02,  1.7268e-02, -3.5463e-02, -3.3512e-02,\n",
       "          -3.4757e-02,  2.6809e-02,  2.7568e-02, -3.2175e-02, -2.7977e-02,\n",
       "          -1.9030e-02, -1.9634e-02,  2.0281e-02, -2.5488e-02,  1.9695e-02,\n",
       "          -1.3523e-02, -1.2671e-02, -3.5121e-02, -1.7322e-03,  2.9218e-02,\n",
       "           2.8852e-02,  2.0200e-04,  2.4895e-02,  3.4763e-02, -1.0970e-02,\n",
       "           2.7115e-02, -5.1297e-03,  2.8992e-03,  1.0168e-03, -3.4649e-03,\n",
       "          -1.1293e-02,  1.0129e-02, -3.2497e-02, -2.7804e-03,  1.5211e-02,\n",
       "          -2.5131e-03, -2.2547e-02,  3.1299e-02, -1.8242e-02,  1.2677e-03,\n",
       "          -3.0431e-02,  3.5708e-02,  9.2714e-03,  3.2711e-02, -1.7168e-02,\n",
       "          -1.4075e-02,  4.8161e-03, -2.1155e-02,  7.8539e-03, -1.4602e-02,\n",
       "          -1.0792e-02,  3.4014e-02, -2.5792e-02,  1.0991e-03, -1.0272e-02,\n",
       "          -3.5025e-02, -6.4404e-03,  2.4474e-02,  1.6962e-02,  3.3324e-02,\n",
       "          -3.4691e-02,  7.2451e-03,  1.5102e-02, -1.2324e-02,  1.8875e-03,\n",
       "          -2.9517e-02, -7.3756e-03, -1.8722e-02, -3.0994e-02, -2.5666e-02,\n",
       "           3.1939e-02,  1.4171e-02, -1.0634e-02, -2.1800e-02,  2.7120e-02,\n",
       "           1.8026e-02, -3.2929e-02,  2.7919e-02, -3.2657e-02,  1.3261e-02,\n",
       "          -9.4228e-03, -1.4176e-02,  5.9103e-03, -2.1585e-03, -3.2445e-02,\n",
       "           1.5749e-02,  1.2742e-02, -1.3797e-02,  2.1233e-02, -8.0747e-03,\n",
       "           2.9446e-02,  2.6829e-02, -1.8000e-02, -1.4475e-02, -3.5434e-02,\n",
       "           3.8344e-03, -1.6550e-02, -6.1961e-03,  1.3501e-02, -2.2057e-02,\n",
       "          -9.0047e-03, -1.5777e-02, -3.1630e-02, -1.2904e-02, -1.5303e-02,\n",
       "           3.0890e-02,  3.1544e-02, -1.5695e-02,  6.5186e-03, -2.5482e-02,\n",
       "          -1.3134e-02, -1.3965e-02,  2.3176e-02,  2.3884e-02,  7.8171e-03,\n",
       "          -1.9680e-02,  1.4698e-03,  1.6433e-02,  9.6249e-03,  1.9685e-02,\n",
       "          -3.3993e-02,  3.4808e-02, -6.6511e-03, -3.0893e-02,  1.2771e-02,\n",
       "          -2.3493e-03,  6.7779e-03, -2.4631e-02,  6.2922e-03,  6.7309e-04,\n",
       "          -1.4774e-02, -3.2119e-02, -2.4361e-02, -1.4880e-02, -1.0447e-02,\n",
       "           1.1186e-02,  1.5181e-02,  5.4227e-03,  1.2195e-02,  2.1014e-02,\n",
       "           1.1692e-02,  8.6253e-03,  4.2875e-03,  3.1171e-02, -1.4533e-02,\n",
       "          -1.0490e-02,  3.0339e-02,  6.0321e-03, -1.1739e-02,  1.3934e-02,\n",
       "           2.8126e-02, -1.8524e-02,  3.3302e-02, -1.0570e-02, -8.1246e-04,\n",
       "          -1.6358e-03, -6.5322e-03, -7.6058e-03,  2.6744e-02,  1.7147e-02,\n",
       "          -2.0961e-02,  3.2247e-02,  3.1873e-02, -1.4112e-02, -3.6101e-03,\n",
       "           2.2210e-02,  2.4122e-02, -2.3592e-02,  1.5760e-02,  2.5032e-02,\n",
       "          -1.9474e-02, -3.0900e-03,  9.4670e-03,  1.2669e-02, -2.0359e-02,\n",
       "          -3.9286e-04, -2.4466e-02,  2.3335e-02,  3.2034e-02, -3.8451e-03,\n",
       "           1.0501e-02,  2.9825e-02, -2.7705e-02,  2.4032e-02,  2.3663e-02,\n",
       "           3.1397e-02,  2.3195e-02, -1.4157e-02, -1.6038e-02,  3.5136e-02,\n",
       "           8.5210e-03, -6.0057e-03, -4.2072e-03,  2.9838e-02,  5.1656e-03,\n",
       "          -5.0640e-03, -1.3243e-02,  4.0835e-03,  3.4618e-02,  2.4800e-02,\n",
       "          -3.3435e-02,  2.8058e-02,  1.7785e-02,  8.2336e-03, -2.8185e-02,\n",
       "           1.7530e-02,  3.3234e-02,  2.8666e-02,  1.8574e-03, -3.5155e-02,\n",
       "          -4.0897e-03,  3.2795e-02, -1.5048e-02,  3.4444e-02, -8.2953e-03,\n",
       "           2.2584e-02, -2.3483e-02,  1.2325e-02,  6.6369e-03, -1.5844e-02,\n",
       "           1.9003e-02,  3.0645e-02, -6.5257e-03, -2.0633e-02,  2.6745e-02,\n",
       "          -1.1915e-02, -1.1830e-02, -4.8796e-03, -2.9973e-02,  3.3624e-02,\n",
       "          -3.8541e-03,  2.4606e-02, -1.2229e-02, -3.2570e-02,  2.5033e-02,\n",
       "           3.2079e-02, -1.7498e-02, -2.3343e-02, -2.5643e-02,  2.0116e-02,\n",
       "          -1.8262e-02,  2.6851e-02,  3.4745e-02,  5.4186e-03,  3.2348e-02,\n",
       "           2.0717e-02,  3.5498e-02, -9.0489e-03,  2.3717e-02,  2.2812e-02,\n",
       "          -2.1906e-02, -1.6184e-02,  2.7387e-02,  6.7002e-03, -2.6072e-02,\n",
       "          -1.2183e-02,  1.5309e-02, -1.8615e-02, -8.8392e-03,  3.3977e-02,\n",
       "          -1.1646e-02, -7.2914e-03,  2.6659e-02,  3.5047e-02, -8.1476e-03,\n",
       "          -3.3592e-02,  3.3255e-02,  2.6533e-02, -2.9911e-02, -3.9631e-03,\n",
       "          -1.2707e-02,  2.3832e-02, -2.3102e-02,  3.5197e-02,  3.3178e-02,\n",
       "          -2.2254e-02,  1.2697e-02,  1.8446e-02,  3.1055e-02,  1.7398e-02,\n",
       "           2.1496e-02, -1.8048e-02, -3.1597e-02, -2.9670e-02, -7.2833e-03,\n",
       "          -1.3496e-02, -1.2062e-02,  9.7165e-03, -2.8750e-03, -4.5783e-03,\n",
       "           1.2604e-02, -1.2258e-02, -2.9560e-02, -1.7287e-02,  2.9393e-02,\n",
       "          -1.7055e-03,  3.1047e-02, -1.4962e-02,  3.0388e-02,  2.4671e-02,\n",
       "          -4.8192e-04, -6.0059e-03, -1.1227e-02, -2.5682e-02, -2.3608e-02,\n",
       "          -3.3864e-02,  2.7008e-02, -1.1210e-02,  3.0230e-02,  2.1225e-02,\n",
       "          -2.1626e-03,  2.0660e-02, -3.0614e-02,  4.3657e-03,  2.8145e-03,\n",
       "          -2.8139e-02,  3.1633e-02, -3.2066e-02,  1.1900e-02, -2.2541e-02,\n",
       "           6.1711e-04,  1.9787e-02,  3.0101e-02, -1.3086e-02,  1.4667e-02,\n",
       "           1.8278e-03, -3.5345e-03, -5.1680e-03, -4.2027e-03,  9.6692e-04,\n",
       "           2.4853e-02, -1.1432e-03,  3.1924e-02, -2.1742e-02, -2.8787e-02,\n",
       "           3.3981e-03,  1.1686e-02,  1.4390e-04,  7.8401e-03,  1.8749e-02,\n",
       "           1.6538e-02,  7.3385e-03, -2.9846e-02,  1.1827e-02, -3.0045e-02,\n",
       "           2.2193e-02,  2.6150e-02, -3.0662e-02, -1.2399e-02, -1.2175e-02,\n",
       "          -3.0893e-02,  1.4419e-02,  5.5360e-03, -2.6300e-03,  3.3426e-02,\n",
       "          -9.3769e-03,  2.7797e-02, -9.6827e-03, -1.9345e-02,  4.4890e-03,\n",
       "           2.1825e-02,  1.1401e-02, -1.8155e-02, -4.8834e-03,  1.5828e-02,\n",
       "           5.4087e-03, -9.3212e-03,  1.2261e-02, -2.7475e-02,  4.8240e-03,\n",
       "           4.0212e-03, -2.6494e-02,  1.8867e-02,  2.3602e-03, -1.2683e-02,\n",
       "           1.9243e-02, -3.2160e-02,  2.6988e-02,  6.1729e-03,  1.1490e-02,\n",
       "          -3.5504e-02, -1.2239e-02,  4.2992e-03,  2.3919e-02, -8.5222e-04,\n",
       "          -2.0544e-02,  3.1178e-02, -1.4401e-02, -2.2724e-02, -1.2221e-02,\n",
       "          -1.4866e-03,  3.5234e-02,  2.8617e-02,  4.4981e-03,  2.1467e-02,\n",
       "           2.2032e-02, -2.3349e-02,  3.3953e-02,  3.3647e-02,  3.9139e-05,\n",
       "          -1.9087e-02,  2.3235e-02, -3.1115e-02,  2.2456e-02, -3.1247e-02,\n",
       "           2.7164e-02,  3.5442e-02,  2.4237e-02,  3.4627e-02,  7.4123e-04,\n",
       "           3.3582e-02, -1.1439e-02,  2.7336e-02, -3.3492e-02,  3.4600e-02,\n",
       "           2.1723e-02, -1.4912e-02, -2.1945e-02, -3.1176e-02,  7.9865e-03,\n",
       "          -2.4721e-02, -3.3198e-02,  3.1487e-02,  1.8371e-03, -1.6644e-02,\n",
       "           2.1638e-02,  1.8742e-02,  3.4893e-02,  1.7095e-02,  1.5618e-02,\n",
       "          -2.7192e-02, -1.8528e-02, -2.8084e-02,  1.1675e-02,  2.1495e-02,\n",
       "          -1.2757e-02, -2.6548e-02], device='cuda:0', requires_grad=True)),\n",
       " ('linear_relu_stack.2.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0324, -0.0043,  0.0411,  ..., -0.0399, -0.0189, -0.0041],\n",
       "          [-0.0408,  0.0091, -0.0331,  ..., -0.0350,  0.0098,  0.0259],\n",
       "          [-0.0075, -0.0128,  0.0175,  ..., -0.0219,  0.0226,  0.0251],\n",
       "          ...,\n",
       "          [-0.0216,  0.0265, -0.0076,  ...,  0.0044,  0.0348,  0.0424],\n",
       "          [ 0.0127,  0.0441,  0.0133,  ...,  0.0328,  0.0200, -0.0266],\n",
       "          [ 0.0092, -0.0261,  0.0061,  ..., -0.0404, -0.0180, -0.0412]],\n",
       "         device='cuda:0', requires_grad=True)),\n",
       " ('linear_relu_stack.2.bias',\n",
       "  Parameter containing:\n",
       "  tensor([ 2.8710e-03, -1.9242e-02,  6.7010e-03,  8.6099e-03, -1.4432e-02,\n",
       "           3.2465e-02,  3.5824e-02,  3.8726e-02, -2.7662e-02, -3.8264e-02,\n",
       "           2.4369e-02,  1.0404e-02,  3.3032e-03, -3.3358e-03, -4.3997e-02,\n",
       "           3.7477e-02,  3.3384e-02, -1.9237e-02, -4.2020e-02, -3.2986e-04,\n",
       "          -3.0724e-02, -3.6443e-02, -1.9178e-02, -2.2542e-02, -1.1641e-02,\n",
       "          -4.4226e-03, -3.3250e-02,  2.8736e-02,  2.5248e-02,  5.4506e-04,\n",
       "          -2.6733e-02, -3.9430e-02, -3.0939e-02, -1.0285e-02,  1.4341e-02,\n",
       "           1.3439e-02, -3.3810e-02, -5.7874e-03, -1.0901e-04,  3.1382e-02,\n",
       "          -2.3576e-02,  2.4011e-02,  3.6587e-02, -1.9139e-02,  1.7564e-02,\n",
       "          -4.8182e-03,  2.8858e-02,  3.3455e-02, -3.9556e-02, -2.9161e-02,\n",
       "          -3.7161e-02,  1.1458e-02, -2.8882e-02,  3.3048e-02, -4.1435e-02,\n",
       "           4.3494e-02,  3.2056e-02,  7.1630e-04, -1.4838e-02, -1.8197e-02,\n",
       "           2.3632e-02,  1.9936e-02,  4.3052e-02,  3.7338e-02,  3.1892e-02,\n",
       "           5.5695e-03, -2.9230e-02,  3.6077e-02,  4.0719e-02, -2.9474e-02,\n",
       "           2.2565e-02,  1.0864e-02, -3.4358e-02, -3.0102e-02,  2.6356e-02,\n",
       "           1.1452e-02, -3.3431e-02,  2.1365e-02, -4.0520e-02,  2.0286e-02,\n",
       "           6.5371e-03,  3.4840e-02,  3.5657e-03, -2.1518e-02, -1.5343e-03,\n",
       "          -1.9481e-03, -1.4430e-02, -1.4739e-02, -3.5918e-02,  2.9510e-03,\n",
       "          -1.8456e-02, -1.4466e-02, -1.7063e-02, -1.0371e-02,  3.4552e-02,\n",
       "          -5.6629e-03,  3.6002e-02, -1.1401e-05, -1.3936e-02, -4.1311e-02,\n",
       "           2.7454e-02, -1.7516e-02,  1.8975e-02, -3.9495e-03, -4.2416e-02,\n",
       "          -1.8929e-02,  1.9491e-02, -3.2488e-02,  3.5211e-02,  1.9470e-02,\n",
       "          -1.4971e-02, -7.5725e-03,  4.1427e-03,  4.2068e-02, -2.7876e-02,\n",
       "          -3.3528e-02, -3.4465e-02, -3.5568e-02, -1.2607e-03, -1.9795e-02,\n",
       "          -1.9031e-02,  3.9877e-02,  2.1095e-02, -3.3147e-02, -3.9990e-02,\n",
       "           9.6456e-03, -6.4018e-03, -2.4118e-02, -2.2029e-02, -3.8417e-02,\n",
       "          -2.6169e-02,  3.5891e-02,  4.0763e-02,  1.4656e-02,  4.1561e-02,\n",
       "          -4.4156e-02, -3.0529e-02, -1.8855e-02, -1.0918e-02,  2.6132e-03,\n",
       "           4.3780e-02, -3.8010e-02, -2.2890e-02, -1.0887e-02,  5.5742e-03,\n",
       "           8.1952e-03,  3.1853e-02,  1.6158e-03,  3.0726e-02, -1.3365e-02,\n",
       "           4.1186e-02, -2.0987e-02,  2.8442e-02, -4.1218e-04,  3.2875e-02,\n",
       "           9.0343e-03, -2.6777e-02, -2.1954e-02, -6.1429e-03,  3.1382e-02,\n",
       "           2.1469e-02, -3.4620e-04, -1.7069e-02, -4.1215e-02,  1.5049e-02,\n",
       "          -2.9988e-02, -2.9790e-02, -2.9730e-02, -2.0851e-02,  1.5123e-03,\n",
       "           3.7155e-02,  2.2927e-02,  2.3839e-02,  2.1210e-02, -1.4617e-02,\n",
       "           4.1474e-02,  5.7785e-03, -2.4566e-02,  1.7543e-02, -2.9173e-02,\n",
       "           3.1091e-02, -1.0423e-02, -1.9339e-03,  1.8141e-02,  1.3000e-02,\n",
       "          -3.4707e-02, -5.7136e-03,  1.5551e-02, -1.5664e-02,  3.6615e-02,\n",
       "          -1.2983e-02, -4.1213e-02,  8.3819e-03,  2.5390e-02, -3.5520e-02,\n",
       "          -7.7787e-03, -4.6501e-03, -8.4415e-03, -3.3993e-02,  3.1482e-03,\n",
       "          -1.6190e-02, -2.7663e-02, -3.3265e-02, -4.4811e-03,  2.9480e-02,\n",
       "          -2.2285e-02,  1.1690e-02, -2.4709e-02,  3.8375e-02, -2.9225e-02,\n",
       "          -4.2593e-02, -1.4390e-02,  1.0952e-02,  1.1832e-03,  2.7447e-02,\n",
       "          -2.6657e-02, -2.8166e-04,  1.3713e-02,  3.9834e-02, -2.2463e-02,\n",
       "          -2.6212e-02,  3.7585e-02, -2.2075e-02,  3.4947e-02, -4.1364e-02,\n",
       "          -2.5801e-02,  2.1192e-02, -1.2445e-02, -5.6806e-03,  4.3294e-02,\n",
       "          -2.5174e-02, -1.9326e-02, -5.1535e-04,  7.9621e-03, -2.0349e-02,\n",
       "           2.8758e-03, -2.8720e-02, -2.2888e-02,  2.4467e-02,  1.5962e-02,\n",
       "           1.6185e-02,  3.9442e-02, -1.0297e-03,  3.8220e-02,  1.4580e-02,\n",
       "           3.8510e-02,  2.8074e-02, -2.2921e-02, -3.4980e-02, -1.1431e-03,\n",
       "          -2.4647e-02, -3.7770e-02, -1.6935e-02, -2.3454e-02, -2.5926e-02,\n",
       "          -1.0234e-02,  4.1712e-02,  1.5912e-02, -1.7321e-03, -1.9371e-02,\n",
       "          -1.1485e-02, -1.2813e-02, -1.6684e-02, -3.2070e-02,  2.7518e-02,\n",
       "           8.5019e-03, -2.9669e-02, -5.1736e-03, -2.0174e-04, -3.3253e-02,\n",
       "           1.9997e-02,  1.8454e-02,  2.4450e-02,  3.6249e-02,  3.8365e-02,\n",
       "           2.8153e-02,  2.4731e-02, -3.7315e-02,  2.3609e-02,  2.5012e-02,\n",
       "           4.0737e-02, -2.1283e-04, -9.0924e-03, -4.3374e-02, -1.1187e-03,\n",
       "           1.4299e-02, -3.9210e-04,  1.4471e-02,  4.3595e-02, -1.3021e-02,\n",
       "           4.0153e-02,  2.2935e-02,  3.1901e-02,  8.1504e-03, -3.3620e-02,\n",
       "           3.8424e-02, -2.0468e-02, -5.1169e-03,  7.7632e-03,  8.3060e-03,\n",
       "           4.3804e-03,  1.0971e-02,  4.3834e-02,  3.1765e-02, -2.4918e-02,\n",
       "           6.0085e-03, -4.1150e-02, -2.5599e-02, -1.0501e-02,  2.1328e-02,\n",
       "          -6.0297e-03,  1.2315e-02, -3.5546e-02, -3.5652e-02, -4.7457e-03,\n",
       "           3.0055e-02,  1.3199e-02,  3.0257e-03,  3.7994e-02, -2.8315e-02,\n",
       "          -4.2910e-02, -2.4935e-02,  4.3833e-03, -6.4376e-03, -5.6186e-03,\n",
       "          -3.2978e-02, -1.3198e-02, -4.4053e-02, -3.2857e-02,  4.4144e-02,\n",
       "           2.4894e-02, -3.9571e-02,  3.9909e-02, -1.2205e-02,  7.0812e-03,\n",
       "           1.7015e-02,  3.7600e-02,  2.4015e-03, -3.0414e-02,  2.1383e-02,\n",
       "          -1.4218e-02, -3.4957e-02,  2.9083e-02,  5.7374e-03, -2.2524e-02,\n",
       "          -2.5314e-02, -7.5229e-03,  4.0539e-02, -3.0892e-02,  2.7999e-02,\n",
       "           2.3225e-02, -5.0900e-03,  3.3077e-02, -4.0138e-02,  4.8443e-03,\n",
       "          -1.2326e-02,  3.5049e-02,  4.2648e-02,  2.9942e-02, -6.1486e-03,\n",
       "          -1.5693e-03, -1.7663e-02,  2.7621e-02, -2.5451e-02, -2.1244e-02,\n",
       "          -1.3568e-02, -1.6313e-02, -3.8418e-02,  3.4929e-03,  3.8897e-02,\n",
       "          -3.9738e-02, -2.1209e-03,  4.0671e-02, -3.3116e-02,  7.0606e-03,\n",
       "          -4.6907e-03, -4.5692e-03, -3.4201e-03, -2.1007e-02, -4.1648e-02,\n",
       "           4.3145e-02, -3.1758e-02, -1.6614e-02, -7.2951e-03, -1.4637e-02,\n",
       "          -2.0133e-02, -1.3815e-02,  3.0488e-02, -1.1988e-02,  3.4930e-02,\n",
       "           3.2256e-02,  3.7642e-02,  1.5605e-02,  3.6550e-03,  3.2058e-02,\n",
       "           2.6636e-02, -2.7245e-02,  3.8224e-02,  1.5982e-02,  3.4608e-02,\n",
       "           1.8019e-03,  3.2358e-02,  2.0930e-02,  3.3913e-02, -1.1236e-02,\n",
       "          -2.1105e-02,  1.2092e-02,  1.5606e-02,  2.0424e-02, -1.6748e-02,\n",
       "           2.5361e-02, -3.6953e-03,  8.9495e-03, -3.5442e-02, -1.6328e-02,\n",
       "          -3.4981e-02, -1.5256e-02, -2.1466e-02, -2.3985e-03,  3.8429e-02,\n",
       "          -2.1387e-02, -3.5788e-02, -1.8132e-02,  3.9183e-02, -2.6323e-02,\n",
       "           3.1292e-02, -3.8456e-02,  4.2532e-02,  2.0210e-03, -1.4897e-02,\n",
       "           7.5786e-04,  3.4949e-02,  3.4826e-02, -4.0351e-02,  2.3705e-02,\n",
       "          -3.5980e-02,  3.5894e-03, -1.3083e-02,  1.0551e-02, -5.5555e-03,\n",
       "           2.2930e-02, -4.3830e-02, -2.5366e-03,  2.2028e-02,  1.2473e-02,\n",
       "          -1.5246e-02,  1.9810e-02,  2.8333e-02, -2.5825e-02,  3.4512e-02,\n",
       "          -7.7064e-04,  3.0000e-02,  2.9333e-02,  3.4223e-03,  5.5881e-04,\n",
       "           2.8825e-02, -6.9095e-03, -1.2403e-02, -2.9510e-02, -2.3047e-02,\n",
       "          -3.5092e-02, -2.1879e-02,  1.2741e-02,  3.1975e-02,  5.6226e-03,\n",
       "           1.0594e-02,  3.3896e-02,  1.1907e-02,  1.5439e-02, -1.3317e-02,\n",
       "           4.0047e-04,  4.3561e-03, -3.2127e-02,  1.9101e-02,  3.3347e-02,\n",
       "          -3.2435e-02,  3.9858e-02, -3.6897e-02, -4.7819e-03, -4.3161e-03,\n",
       "           1.8739e-02,  1.6173e-02, -4.1383e-02, -1.2102e-02, -4.7591e-03,\n",
       "          -1.5461e-03, -4.3113e-02, -1.9221e-02, -4.5409e-03,  2.3288e-02,\n",
       "           2.9263e-02, -7.5259e-03,  6.0277e-03,  3.9554e-02,  3.6920e-03,\n",
       "          -2.5204e-02, -2.1233e-02,  4.0461e-02, -2.3580e-03,  1.5237e-02,\n",
       "          -2.6380e-02, -1.1257e-02,  9.1225e-03,  1.8858e-02,  1.1681e-03,\n",
       "           4.1634e-02,  2.9284e-02,  1.6810e-02, -3.5802e-02, -1.5751e-02,\n",
       "           2.0490e-02,  6.1023e-03], device='cuda:0', requires_grad=True)),\n",
       " ('linear_relu_stack.4.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0409,  0.0398, -0.0085,  ..., -0.0210,  0.0300, -0.0099],\n",
       "          [-0.0354, -0.0121,  0.0128,  ...,  0.0204, -0.0325, -0.0368],\n",
       "          [-0.0126,  0.0020, -0.0062,  ..., -0.0372,  0.0036,  0.0157],\n",
       "          ...,\n",
       "          [-0.0257, -0.0383, -0.0151,  ..., -0.0183,  0.0058, -0.0289],\n",
       "          [ 0.0418,  0.0308, -0.0086,  ...,  0.0189, -0.0182, -0.0273],\n",
       "          [-0.0394, -0.0055, -0.0142,  ...,  0.0182,  0.0294,  0.0033]],\n",
       "         device='cuda:0', requires_grad=True)),\n",
       " ('linear_relu_stack.4.bias',\n",
       "  Parameter containing:\n",
       "  tensor([-0.0268,  0.0384, -0.0197, -0.0411, -0.0066,  0.0424,  0.0006, -0.0123,\n",
       "           0.0327,  0.0265], device='cuda:0', requires_grad=True))]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.named_parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e841c2a-6f5e-4cec-8080-d55711b9004c",
   "metadata": {},
   "source": [
    "Lets go through the transformations manually and see what happens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "96a5e8c6-9715-4342-bb72-cb2b3bca43a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image = torch.rand(3,28,28)\n",
    "flatten = nn.Flatten()\n",
    "flat_image = flatten(input_image)\n",
    "layer1 = nn.Linear(in_features=28*28, out_features=20)\n",
    "hidden1 = layer1(flat_image)\n",
    "relu = nn.ReLU()\n",
    "hidden1_relu = relu(hidden1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ea85bd40-b4db-4727-9ea1-0880ea9c3fe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.4047, 0.3265, 0.9336,  ..., 0.9449, 0.2127, 0.5980],\n",
       "          [0.1530, 0.2212, 0.6325,  ..., 0.8357, 0.7831, 0.6753],\n",
       "          [0.6460, 0.1714, 0.4423,  ..., 0.8541, 0.2490, 0.9009],\n",
       "          ...,\n",
       "          [0.7913, 0.8038, 0.2167,  ..., 0.0418, 0.6079, 0.9968],\n",
       "          [0.6320, 0.1235, 0.1826,  ..., 0.5830, 0.2637, 0.2465],\n",
       "          [0.0547, 0.5544, 0.8689,  ..., 0.1137, 0.7727, 0.9784]],\n",
       " \n",
       "         [[0.9554, 0.1592, 0.2311,  ..., 0.1519, 0.8800, 0.5123],\n",
       "          [0.2088, 0.0072, 0.0413,  ..., 0.6915, 0.0325, 0.2674],\n",
       "          [0.2771, 0.5601, 0.5384,  ..., 0.6019, 0.4632, 0.0047],\n",
       "          ...,\n",
       "          [0.5246, 0.6885, 0.6237,  ..., 0.6351, 0.1440, 0.3297],\n",
       "          [0.8154, 0.7596, 0.3202,  ..., 0.2589, 0.9657, 0.6551],\n",
       "          [0.8759, 0.0815, 0.3772,  ..., 0.0349, 0.7726, 0.5019]],\n",
       " \n",
       "         [[0.1588, 0.3539, 0.5743,  ..., 0.1617, 0.4004, 0.7798],\n",
       "          [0.6482, 0.7424, 0.2814,  ..., 0.0768, 0.1063, 0.1109],\n",
       "          [0.8949, 0.9843, 0.9782,  ..., 0.2516, 0.7430, 0.5402],\n",
       "          ...,\n",
       "          [0.9704, 0.6233, 0.1998,  ..., 0.0102, 0.5692, 0.7884],\n",
       "          [0.1824, 0.1288, 0.0551,  ..., 0.5525, 0.1515, 0.8801],\n",
       "          [0.4817, 0.3389, 0.0424,  ..., 0.3773, 0.9325, 0.9361]]]),\n",
       " torch.Size([3, 28, 28]))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_image, input_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f8ad57da-9828-42e3-80b1-42344754170d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.4047, 0.3265, 0.9336,  ..., 0.1137, 0.7727, 0.9784],\n",
       "         [0.9554, 0.1592, 0.2311,  ..., 0.0349, 0.7726, 0.5019],\n",
       "         [0.1588, 0.3539, 0.5743,  ..., 0.3773, 0.9325, 0.9361]]),\n",
       " torch.Size([3, 784]))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_image, flat_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "485ddba5-e830-4c35-981e-3ebed17e32c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.2594, -0.0765, -0.7092, -0.1715,  0.0937, -0.1292, -0.2596, -0.0565,\n",
       "          -0.0399,  0.3109,  0.3510, -0.0388, -0.1398, -0.2954,  0.0936,  0.1403,\n",
       "          -0.1770, -0.2248,  0.1037,  0.5428],\n",
       "         [ 0.1227, -0.2223,  0.0086, -0.2165,  0.5908, -0.2631, -0.5805, -0.1244,\n",
       "          -0.0355,  0.5415,  0.0993, -0.3688, -0.0882, -0.4390,  0.3960,  0.2425,\n",
       "          -0.2355, -0.0672,  0.1070,  0.5454],\n",
       "         [ 0.0835,  0.2384, -0.7010,  0.0251,  0.6562, -0.1876, -0.4529, -0.2066,\n",
       "           0.2494,  0.7765,  0.1737,  0.2156,  0.1488, -0.3757,  0.4363,  0.3504,\n",
       "          -0.3304,  0.0879, -0.1116,  0.6818]], grad_fn=<AddmmBackward0>),\n",
       " torch.Size([3, 20]))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden1, hidden1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ee1094dc-353a-4e97-89e9-41184840d2b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.2594, 0.0000, 0.0000, 0.0000, 0.0937, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.3109, 0.3510, 0.0000, 0.0000, 0.0000, 0.0936, 0.1403, 0.0000, 0.0000,\n",
       "          0.1037, 0.5428],\n",
       "         [0.1227, 0.0000, 0.0086, 0.0000, 0.5908, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.5415, 0.0993, 0.0000, 0.0000, 0.0000, 0.3960, 0.2425, 0.0000, 0.0000,\n",
       "          0.1070, 0.5454],\n",
       "         [0.0835, 0.2384, 0.0000, 0.0251, 0.6562, 0.0000, 0.0000, 0.0000, 0.2494,\n",
       "          0.7765, 0.1737, 0.2156, 0.1488, 0.0000, 0.4363, 0.3504, 0.0000, 0.0879,\n",
       "          0.0000, 0.6818]], grad_fn=<ReluBackward0>),\n",
       " torch.Size([3, 20]))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden1_relu, hidden1_relu.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2acb2d5e-e3ac-4ee3-a0ef-9226d5a4fc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_modules = nn.Sequential(\n",
    "    flatten,\n",
    "    layer1,\n",
    "    relu,\n",
    ")\n",
    "logits = seq_modules(input_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "18bce083-0f2d-45e4-844b-b75d2ad5a5ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.2594, 0.0000, 0.0000, 0.0000, 0.0937, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.3109, 0.3510, 0.0000, 0.0000, 0.0000, 0.0936, 0.1403, 0.0000, 0.0000,\n",
       "          0.1037, 0.5428],\n",
       "         [0.1227, 0.0000, 0.0086, 0.0000, 0.5908, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.5415, 0.0993, 0.0000, 0.0000, 0.0000, 0.3960, 0.2425, 0.0000, 0.0000,\n",
       "          0.1070, 0.5454],\n",
       "         [0.0835, 0.2384, 0.0000, 0.0251, 0.6562, 0.0000, 0.0000, 0.0000, 0.2494,\n",
       "          0.7765, 0.1737, 0.2156, 0.1488, 0.0000, 0.4363, 0.3504, 0.0000, 0.0879,\n",
       "          0.0000, 0.6818]], grad_fn=<ReluBackward0>),\n",
       " torch.Size([3, 20]))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits, logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8a2595db-4b3c-4689-9508-0f4287654421",
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax = nn.Softmax(dim=1)\n",
    "pred_probab = softmax(logits)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
